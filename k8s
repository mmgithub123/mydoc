指定config
kubectl --kubeconfig=kube/config get ingress

查看service：
kubectl --kubeconfig=kube/config describe services xxx-service

kubectl get pods

describe可以查看每一资源的详细创建信息：
kubectl --kubeconfig= describe pvc prometheus  
kubectl describe pod pod-name -o wide

端口代理：
kubectl --kubeconfig=kube/config port-forward prometheus-75d9c55b77-qqs48 --address 0.0.0.0  8080:9090  -n kube-ops

查看pod日志
kubectl logs pod-name (-n namespace-name)

指定容器执行命令
kubectl exec pod-name -c container-name useing-command

kubectl  exec -it pod-name -n namespace-name bash(sh or /bin/sh or /bin/bash)

查看yaml
kubectl get pod -n namespace-name -o yaml


----------------------------------------------------------------------------------------------
监控报警

JobDown
对应Prometheus指标收集的4个Job、分别为kube-state-metrics、kube-node-exporter、kube-node-kubelet、kube-node-cadvisor，一旦哪个Job有问题，则会进行告警。
PodDown
当处于Running状态的pod停止时，则会进行告警。
PodReady
在Pod重新调度后，虽然Pod处于Running状态，由于此时正在重启，Ready为0，只有当readiness探针探测正常后，Ready为1，才会正式接受请求；因此Ready长时间为0时，说明Pod启动有问题，需要进行告警。
PodRestart
当Pod健康检查不成功，Pod会进行不断的重启，一旦超过一定的次数，则说明Pod有问题，此时需要进行告警。


pod状态：
Pending，  Running ， Succeeded ， Failed，Unknown

容器状态：
Waiting, Running, and Terminated

pod条件：
PodScheduled: the Pod has been scheduled to a node.
ContainersReady: all containers in the Pod are ready.
Initialized: all init containers have started successfully.
Ready: the Pod is able to serve requests and should be added to the load balancing pools of all matching Services.


Google在“SRE Handbook”中以“四个黄金信号”的概念为我们提供了一个论述：
Latency — 延迟
Traffic — 流量
Errors — 错误数
Saturation — 饱和度

Tom Wilkie解释RED方法为：
Rate：每秒的请求数。
Errors：失败的那些请求的数量。
Duration：这些请求所花费的时间。
USE方法用于资源，RED方法用于服务  — Tom Wilkie


cadvisor              ，kubelet container
metric-server         ，focused on implementing the resource metrics API: CPU, file descriptors, memory, request latencies, etc.
kube-state-metrics    ，focused on orchestration metadata: deployment, pod, replica status, etc.
node-exporter         ，node

cAdvisor is an open source container resource usage and performance analysis agent. 
It is purpose-built for containers and supports Docker containers natively. 
In Kubernetes, cAdvisor runs as part of the Kubelet binary. So, any aggregator retrieving “node local” and
 Docker metrics will directly scrape the Kubelet Prometheus endpoints.

Kube-state-metrics is a simple service that listens to the Kubernetes API server and generates metrics about 
the state of the objects such as deployments, nodes, and pods. It is important to note that kube-state-metrics is 
just a metrics endpoint. Other entities need to scrape it and provide long term storage (e.g., the Prometheus server).

Metrics-server is a cluster-wide aggregator of resource usage data. The metrics server will only present 
the last data points and it’s not in charge of long term storage.

对于集群的监控一般我们需要考虑以下几个方面：

Kubernetes 节点的监控：比如节点的 cpu、load、disk、memory 等指标
内部系统组件的状态：比如 kube-scheduler、kube-controller-manager、kubedns/coredns 等组件的详细运行状态
编排级的 metrics：比如 Deployment 的状态、资源请求、调度和 API 延迟等数据指标

--------------------------------------------------------------------------------------------------------------
altermanager：

· Inactive：这里什么都没有发生。
· Pending：已触发阈值，但未满足告警持续时间（即rule中的for字段）
· Firing：已触发阈值且满足告警持续时间。警报发送到Notification Pipeline，经过处理，发送给接受者这样目的是多次判断失败才发告警，减少邮件。
  resolved

告警处理：
分组
抑制
静默

告警级别：
critical  紧急
error     重要
warn      次要
info      提示

------------------------------------------------------------------------------------------------------------
实施：
prometheus触发一条告警的过程：
prometheus--->触发阈值--->超出持续时间--->alertmanager--->分组|抑制|静默--->媒体类型--->邮件|钉钉|微信等。

https://zhuanlan.zhihu.com/p/372271667
https://www.infoq.cn/article/Uj12kNwoRCwG0kke8Zfv
https://mp.weixin.qq.com/s?__biz=MzkwOTIxNDQ3OA==&mid=2247532438&idx=1&sn=bb332ead7ab472cc49bcb13658817b49&source=41#wechat_redirect

https://www.cnblogs.com/xzkzzz/p/10208115.html   得创建PV PVC
https://phoenixnap.com/kb/prometheus-kubernetes-monitoring
https://devopscube.com/setup-prometheus-monitoring-on-kubernetes/   
得注意权限
剩下基本是apply  yaml

报警通知详细设置label：
https://www.bonial.com/tech-blog/routing-prometheus-alerts-in-multi-tenant-kubernetes-clusters/
https://prometheus.io/docs/prometheus/latest/querying/operators/#many-to-one-and-one-to-many-vector-matches  语法

promethues reload:
curl -XPOST http://10.88.153.80:32035/-/reload

服务发现：
官网：https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config
kubernetes_sd_configs
# The API server addresses. If left empty, Prometheus is assumed to run inside
# of the cluster and will discover API servers automatically and use the pod's
# CA certificate and bearer token file at /var/run/secrets/kubernetes.io/serviceaccount/.
[ api_server: <host> ]
To discover targets from another Kubernetes cluster, you need to pass the api_server URL as well as TLS certificate or bearer token files for Prometheus to authenticate.

kubernetes_sd_configs表示基于Kubernetes进行服务发现，
而其中的role字段可为pod，node, service, endpoints, ingress
Prometheus会创建Kubernetes Client对role中指定的资源对象进行监听。
一般Prometheus部署在Kubernetes集群中的话，Prometheus可以直接利用指定的Service Account对Kubernetes API进行访问。
若Prometheus在Kubernetes集群之外，则kubernetes_sd_configs还需指定监控集群的API Server的URL以及相关的认证信息，从而能够创建对应集群的Client。
和Kubernetes内置的各种Controller类似，当目标资源对象为Pod时，Prometheus会对Kubernetes中的Pod进行List & Watch。每当集群中新增一个Pod，Prometheus就会对其进行处理，
根据其配置创建一个target group。之后，Prometheus会遍历Pod中的每个Container：若Container没有暴露端口，则将一个Container作为一个target并将该target的__address__直接设置为Pod的IP地址；
若Container暴露了一个或多个端口，则将每个端口设置为一个target且target的__address设置为Pod IP加对应端口的组合。如上文所述，一个target group中的targets会共享某些labels，
当target group对应的是一个pod时，Prometheus会将Pod的基本信息作为共享labels。例如：__meta_kubernetes_namespace对应Pod所在的namespace，__meta_kubernetes_pod_name对应pod name，
以及pod的ip，labels和annotations都会作为共享labels写入

已知targets本质上是一系列的labels，因此我们可以根据labels是否符合某些规则实现对targets的过滤，在Prometheus中，这一机制叫做relabel。
一个抓取对象，即target，在Prometheus是用一系列labels来描述的，全局的配置文件描述了某些targets的公共配置，
而Kubernetes等系统的服务发现能力则为Prometheus提供了targets的大部分配置信息。最终，我们可以通过relabel机制对targets对象进行修改过滤，
从而实现对于有效target的抓取。而对于target的抓取，本质上是通过target中的__scheme__，__address__和__metrcis_path__这几个label，
拼凑出一个URL，比如http://10.32.0.2/metrics，对该URL发起一个GET请求，获取监控数据

配置：
# A scrape configuration for running Prometheus on a Kubernetes cluster.
# This uses separate scrape configs for cluster components (i.e. API server, node)
# and services to allow each to use different authentication configs.
#
# Kubernetes labels will be added as Prometheus labels on metrics via the
# `labelmap` relabeling action.
#
# If you are using Kubernetes 1.7.2 or earlier, please take note of the comments
# for the kubernetes-cadvisor job; you will need to edit or remove this job.

# Scrape config for API servers.
#
# Kubernetes exposes API servers as endpoints to the default/kubernetes
# service so this uses `endpoints` role and uses relabelling to only keep
# the endpoints associated with the default/kubernetes service using the
# default named port `https`. This works for single API server deployments as
# well as HA API server deployments.
scrape_configs:
- job_name: 'kubernetes-apiservers'

  kubernetes_sd_configs:
  - role: endpoints

  # Default to scraping over https. If required, just disable this or change to
  # `http`.
  scheme: https

  # This TLS & bearer token file config is used to connect to the actual scrape
  # endpoints for cluster components. This is separate to discovery auth
  # configuration because discovery & scraping are two separate concerns in
  # Prometheus. The discovery auth config is automatic if Prometheus runs inside
  # the cluster. Otherwise, more config options have to be provided within the
  # <kubernetes_sd_config>.
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    # If your node certificates are self-signed or use a different CA to the
    # master CA, then disable certificate verification below. Note that
    # certificate verification is an integral part of a secure infrastructure
    # so this should only be disabled in a controlled environment. You can
    # disable certificate verification by uncommenting the line below.
    #
    # insecure_skip_verify: true
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

  # Keep only the default/kubernetes service endpoints for the https port. This
  # will add targets for each API server which Kubernetes adds an endpoint to
  # the default/kubernetes service.
  relabel_configs:
  - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
    action: keep
    regex: default;kubernetes;https

# Scrape config for nodes (kubelet).
#
# Rather than connecting directly to the node, the scrape is proxied though the
# Kubernetes apiserver.  This means it will work if Prometheus is running out of
# cluster, or can't connect to nodes for some other reason (e.g. because of
# firewalling).
- job_name: 'kubernetes-nodes'

  # Default to scraping over https. If required, just disable this or change to
  # `http`.
  scheme: https

  # This TLS & bearer token file config is used to connect to the actual scrape
  # endpoints for cluster components. This is separate to discovery auth
  # configuration because discovery & scraping are two separate concerns in
  # Prometheus. The discovery auth config is automatic if Prometheus runs inside
  # the cluster. Otherwise, more config options have to be provided within the
  # <kubernetes_sd_config>.
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

  kubernetes_sd_configs:
  - role: node

  relabel_configs:
  - action: labelmap
    regex: __meta_kubernetes_node_label_(.+)
  - target_label: __address__
    replacement: kubernetes.default.svc:443
  - source_labels: [__meta_kubernetes_node_name]
    regex: (.+)
    target_label: __metrics_path__
    replacement: /api/v1/nodes/${1}/proxy/metrics

# Scrape config for Kubelet cAdvisor.
#
# This is required for Kubernetes 1.7.3 and later, where cAdvisor metrics
# (those whose names begin with 'container_') have been removed from the
# Kubelet metrics endpoint.  This job scrapes the cAdvisor endpoint to
# retrieve those metrics.
#
# In Kubernetes 1.7.0-1.7.2, these metrics are only exposed on the cAdvisor
# HTTP endpoint; use "replacement: /api/v1/nodes/${1}:4194/proxy/metrics"
# in that case (and ensure cAdvisor's HTTP server hasn't been disabled with
# the --cadvisor-port=0 Kubelet flag).
#
# This job is not necessary and should be removed in Kubernetes 1.6 and
# earlier versions, or it will cause the metrics to be scraped twice.
- job_name: 'kubernetes-cadvisor'

  # Default to scraping over https. If required, just disable this or change to
  # `http`.
  scheme: https

  # This TLS & bearer token file config is used to connect to the actual scrape
  # endpoints for cluster components. This is separate to discovery auth
  # configuration because discovery & scraping are two separate concerns in
  # Prometheus. The discovery auth config is automatic if Prometheus runs inside
  # the cluster. Otherwise, more config options have to be provided within the
  # <kubernetes_sd_config>.
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

  kubernetes_sd_configs:
  - role: node

  relabel_configs:
  - action: labelmap
    regex: __meta_kubernetes_node_label_(.+)
  - target_label: __address__
    replacement: kubernetes.default.svc:443
  - source_labels: [__meta_kubernetes_node_name]
    regex: (.+)
    target_label: __metrics_path__
    replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

# Scrape config for service endpoints.
#
# The relabeling allows the actual service scrape endpoint to be configured
# via the following annotations:
#
# * `prometheus.io/scrape`: Only scrape services that have a value of `true`
# * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
# to set this to `https` & most likely set the `tls_config` of the scrape config.
# * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
# * `prometheus.io/port`: If the metrics are exposed on a different port to the
# service then set this appropriately.
- job_name: 'kubernetes-service-endpoints'

  kubernetes_sd_configs:
  - role: endpoints

  relabel_configs:
  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
    action: keep
    regex: true
  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
    action: replace
    target_label: __scheme__
    regex: (https?)
  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
    action: replace
    target_label: __metrics_path__
    regex: (.+)
  - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
    action: replace
    target_label: __address__
    regex: ([^:]+)(?::\d+)?;(\d+)
    replacement: $1:$2
  - action: labelmap
    regex: __meta_kubernetes_service_label_(.+)
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: kubernetes_namespace
  - source_labels: [__meta_kubernetes_service_name]
    action: replace
    target_label: kubernetes_name

# Example scrape config for probing services via the Blackbox Exporter.
#
# The relabeling allows the actual service scrape endpoint to be configured
# via the following annotations:
#
# * `prometheus.io/probe`: Only probe services that have a value of `true`
- job_name: 'kubernetes-services'

  metrics_path: /probe
  params:
    module: [http_2xx]

  kubernetes_sd_configs:
  - role: service

  relabel_configs:
  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
    action: keep
    regex: true
  - source_labels: [__address__]
    target_label: __param_target
  - target_label: __address__
    replacement: blackbox-exporter.example.com:9115
  - source_labels: [__param_target]
    target_label: instance
  - action: labelmap
    regex: __meta_kubernetes_service_label_(.+)
  - source_labels: [__meta_kubernetes_namespace]
    target_label: kubernetes_namespace
  - source_labels: [__meta_kubernetes_service_name]
    target_label: kubernetes_name

# Example scrape config for probing ingresses via the Blackbox Exporter.
#
# The relabeling allows the actual ingress scrape endpoint to be configured
# via the following annotations:
#
# * `prometheus.io/probe`: Only probe services that have a value of `true`
- job_name: 'kubernetes-ingresses'

  metrics_path: /probe
  params:
    module: [http_2xx]

  kubernetes_sd_configs:
    - role: ingress

  relabel_configs:
    - source_labels: [__meta_kubernetes_ingress_annotation_prometheus_io_probe]
      action: keep
      regex: true
    - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]
      regex: (.+);(.+);(.+)
      replacement: ${1}://${2}${3}
      target_label: __param_target
    - target_label: __address__
      replacement: blackbox-exporter.example.com:9115
    - source_labels: [__param_target]
      target_label: instance
    - action: labelmap
      regex: __meta_kubernetes_ingress_label_(.+)
    - source_labels: [__meta_kubernetes_namespace]
      target_label: kubernetes_namespace
    - source_labels: [__meta_kubernetes_ingress_name]
      target_label: kubernetes_name

# Example scrape config for pods
#
# The relabeling allows the actual pod scrape endpoint to be configured via the
# following annotations:
#
# * `prometheus.io/scrape`: Only scrape pods that have a value of `true`
# * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
# * `prometheus.io/port`: Scrape the pod on the indicated port instead of the
# pod's declared ports (default is a port-free target if none are declared).
- job_name: 'kubernetes-pods'

  kubernetes_sd_configs:
  - role: pod

  relabel_configs:
  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
    action: keep
    regex: true
  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
    action: replace
    target_label: __metrics_path__
    regex: (.+)
  - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
    action: replace
    regex: ([^:]+)(?::\d+)?;(\d+)
    replacement: $1:$2
    target_label: __address__
  - action: labelmap
    regex: __meta_kubernetes_pod_label_(.+)
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: kubernetes_namespace
  - source_labels: [__meta_kubernetes_pod_name]
    action: replace
    target_label: kubernetes_pod_name

kubernetes-apiservers
该项主要是让prometheus程序可以访问kube-apiserver，进而进行服务发现。看一下服务发现的代码可以看出，主要服务发现：node，service，ingress，pod，endpoints
kubernetes-nodes
发现node以后，通过/api/v1/nodes/${1}/proxy/metrics来获取node的metrics。
kubernetes-cadvisor
cadvisor已经被集成在kubelet中，所以发现了node就相当于发现了cadvisor。通过 /api/v1/nodes/${1}/proxy/metrics/cadvisor采集容器指标
kubernetes-services和kubernetes-ingresses
该两种资源监控方式差不多，都是需要安装black-box，然后类似于探针去定时访问，根据返回的http状态码来判定service和ingress的服务可用性。
kubernetes-pods
对于pod的监测也是需要加注解：
prometheus.io/scrape，为true则会将pod作为监控目标。
prometheus.io/path，默认为/metrics
prometheus.io/port , 端口
所以看到此处可以看出，该job并不是监控pod的指标，pod已经通过前面的cadvisor采集。此处是对pod中应用的监控。写过exporter的人应该对这个概念非常清楚。
通俗讲，就是你pod中的应用提供了prometheus的监控功能，加上对应的注解，那么该应用的metrics会定时被采集走。
kubernetes-service-endpoints
对于服务的终端节点，也需要加注解：
prometheus.io/scrape，为true则会将pod作为监控目标。
prometheus.io/path，默认为/metrics
prometheus.io/port , 端口
prometheus.io/scheme 默认http，如果为了安全设置了https，此处需要改为https
这个基本上同上的。采集service-endpoints的metrics。
参考：https://segmentfault.com/a/1190000013230914
官方例子：
https://github.com/prometheus/prometheus/blob/main/documentation/examples/prometheus-kubernetes.yml

---------------------------------------------------------------------------------------------------------------------------------------------------------

Counter
This represents a cumulative metric that only increases over time, like the number of requests to an endpoint.
Note: instead of using Counter to instrument decreasing values, use Gauges.

Gauge
Gauges are instantaneous measurements of a value. They can be arbitrary values which will be recorded.
Gauges represent a random value that can increase and decrease randomly such as the load of your system.

Histogram
A histogram samples observations (usually things like request durations or response sizes) and counts them in configurable buckets. 
It also provides a sum of all observed values.
A histogram with a base metric name of exposes multiple time series during a scrape:

---------------------------------------------------------------------------------------------------------------
指标：

报警规则：https://awesome-prometheus-alerts.grep.to/rules#prometheus-self-monitoring
         https://help.aliyun.com/document_detail/176180.html?spm=a2c4g.11186623.4.5.717e3eebxbWsZy#title-dcc-mv9-w33

计时器，计数器

指标，周期，持续时间

端口存活
进程存活
http状态码
主机存活（ping）

1，cpu使用大于80%，100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100) > 80，CPU load is > 80%
2，cpu st 大于10%，avg by(instance) (rate(node_cpu_seconds_total{mode="steal"}[5m])) * 100 > 10，
CPU steal is > 10%. A noisy neighbor is killing VM performances or a spot instance may be out of credit.

内存利用率超过80%
内存压力，rate(node_vmstat_pgmajfault[1m]) > 1000，The node is under heavy memory pressure. High rate of major page faults

入口流量太大，sum by (instance) (rate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 100，Host network interfaces are probably receiving too much data (> 100 MB/s)
出口流量太大，sum by (instance) (rate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 100，Host network interfaces are probably sending too much data (> 100 MB/s)

1，磁盘读流量太大，sum by (instance) (rate(node_disk_read_bytes_total[2m])) / 1024 / 1024 > 50，Disk is probably reading too much data (> 50 MB/s)
2，磁盘写流量太大，sum by (instance) (rate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 50，Disk is probably writing too much data (> 50 MB/s)
3，磁盘满了，
(node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0，Disk is almost full (< 10% left)
4，inodes满了，
node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 
and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0
Disk is almost running out of available inodes (< 10% left)
5，磁盘读延迟，rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 0.1 and rate(node_disk_reads_completed_total[1m]) > 0
Disk latency is growing (read operations > 100ms)
6，磁盘写延迟，rate(node_disk_write_time_seconds_total[1m]) / rate(node_disk_writes_completed_total[1m]) > 0.1 and rate(node_disk_writes_completed_total[1m]) > 0
Disk latency is growing (write operations > 100ms)
7，

Google在“SRE Handbook”中以“四个黄金信号”的概念为我们提供了一个论述：
Latency — 延迟
Traffic — 流量
Errors — 错误数
Saturation — 饱和度

Tom Wilkie解释RED方法为：
Rate：每秒的请求数。
Errors：失败的那些请求的数量。
Duration：这些请求所花费的时间。
USE方法用于资源，RED方法用于服务  — Tom Wilkie

告警名称
 并发用户数
 TPS（QPS） 
 响应时间（95RT或ART） 
 Error% 
 Full GC 
 线程池、任务队列 
异常重启
自定义事件
error log

告警名称	告警阈值	告警频率	告警等级
CPU使用率	平均值 >= 80%	持续3个周期 则告警 每1天告警一次	重要
CPU空闲时间占比	平均值 < 20%	持续3个周期 则告警 每1天告警一次	重要
5分钟平均负载	平均值 > 1.4 x cpu核数	持续3个周期 则告警 每1天告警一次	重要
内存使用率 	平均值 > 80%	持续3个周期 则告警 每1天告警一次	重要
inode已使用占比 	平均值 > 90%	持续3个周期 则告警 每1天告警一次	重要
磁盘使用率	平均值 > 90%	持续3个周期 则告警 每1天告警一次	重要
磁盘I/O使用率	平均值 > 90%	持续3个周期 则告警 每1天告警一次	重要
带内网络流出速率	平均值 > 90%	持续3个周期 则告警 每1天告警一次	重要
带内网络流入速率	平均值 > 90%	持续3个周期 则告警 每1天告警一次	重要


mysql:
告警名称	告警阈值	告警频率	告警等级
内存使用率  	原始值 > 90%	持续1个周期 则告警 每5分钟告警一次	紧急
缓冲池命中率  	原始值 <= 0.9 比率	持续1个周期 则告警 每5分钟告警一次	紧急
慢日志个数统计  	原始值 >= 100 个/分钟	持续1个周期 则告警 每5分钟告警一次	紧急
MDL锁数量  	原始值 >= 5 Count	持续1个周期 则告警 每5分钟告警一次	紧急
硬盘写耗时  	原始值 >= 10 毫秒	持续1个周期 则告警 每1天告警一次	紧急
当前活跃连接数  	原始值 >= 100 个	持续1个周期 则告警 每5分钟告警一次	紧急
磁盘利用率 	原始值 > 90%	持续1个周期 则告警 每5分钟告警一次	紧急
等待线程数  	原始值 >= 20 个数	持续1个周期 则告警 每5分钟告警一次	紧急
实时复制时延  	原始值 >= 60 秒	持续1个周期 则告警 每5分钟告警一次	紧急
硬盘读耗时  	原始值 >= 10 毫秒	持续1个周期 则告警 每5分钟告警一次	紧急
当前行锁等待数  	原始值 >= 10 个数	持续1个周期 则告警 每5分钟告警一次	紧急
CPU使用率 	原始值 > 85%	持续1个周期 则告警 每5分钟告警一次	紧急
连接数使用率 	原始值 >= 80%	持续1个周期 则告警 每5分钟告警一次	紧急
告警名称	告警阈值	告警频率	告警等级
连接数使用率 	原始值 >= 50%	持续3个周期 则告警 每5分钟告警一次	重要
数据库总连接数 	原始值 >= 400 个	持续3个周期 则告警 每5分钟告警一次	重要
内存使用率 	原始值 >= 80%	持续3个周期 则告警 每5分钟告警一次	重要
慢日志个数统计 	原始值 >= 50 个/分钟	持续3个周期 则告警 每5分钟告警一次	重要
缓冲池命中率 	原始值 <= 0.95 比率	持续3个周期 则告警 每5分钟告警一次	重要
TPS 	原始值 >= 2000 次/秒	持续3个周期 则告警 每5分钟告警一次	重要
磁盘利用率 	原始值 >= 80%	持续1个周期 则告警 每1天告警一次	重要
QPS 	原始值 >= 10000 次/秒	持续3个周期 则告警 每5分钟告警一次	重要
活跃连接数 	原始值 >= 50 个	持续3个周期 则告警 每5分钟告警一次	重要
CPU使用率 	原始值 >= 80%	持续3个周期 则告警 每5分钟告警一次	重要
平均复制时延 	原始值 >= 2 s	持续3个周期 则告警 每5分钟告警一次	重要


可观察：
1. 日志是否正确挂载
2. 是否有接入 skywalking ，采集的指标是否满足
3. 是否配置了告警策略
  1. 节点：cpu，内存，磁盘，句柄数
  2. 集群：pod 数量
  3. 容器服务：状态，cpu，内存
4. java dump 文件获取 
  1. 可将 dump 上传到 OSS，提供用户下载地址
  
 
 可灰度：
 1. 负载副本数大于 1，保障灰度更新时候服务的稳定
2. 是否有业务级别的 A/B 测试
3. 是否有可控的灰度（按百分比，地区，特定人群等）能力

可回滚：
1. 应用是否进行版本控制
2. 配置是否进行版本控制

可保护：
1. 是否有限流措施
2. 是否有熔断措施
3. 是否有健康检查
  1. Liveness
  2. Readness
4. 是否有优雅退出策略(宣贯)
5. Docker 首进程不应该是应用进程，需要专门的初始进程如 tini
  1. 如果首进程是业务进程，登录容器无法查看到进程信息，linux有限制
  2. 容器退出时的 kill 15 命令会通知首进程，首进程应该要有能将该信息传递给子进程的能力。
6. Pod 是否配置了不同 Node 的亲和策略
7. 是否跨区域部署
8. Pod 应用是否是非 root 用户
9. 集群访问权限是否限制
  1. 节点 SSH 权限
  2. Kubectl 配置文件权限细粒度划分
10. 部署权限
  1. 发布权限限制
  2. 发布记录审计


可控成本：
1. Pod 规格限额配置
  1. Limit
  2. Request
2. 命名空间限额
3. 节点机器购买、退订流程指南
4. 成本费用看板


易于运维：
1. 新节点 Node 是否有初始化的脚本工具
  1. 句柄数调整
  2. 节点 pod 数量调整
  3. 进程线程数调整
  4. 节点无用镜像的定时删除
2. 是否有完善的问题排查工具
  1. Web-kubectl 访问平台，并且根据用户有权限约束
  2. Web-shell 平台，在线直接访问容器
  3. Dockerfile 封装常用的排查工具
  4. Skywalking、AOP 监控平台协助排查
3. 机器节点池预备
  1. 现在节点很少，某个机器故障，集群负载就不够，为了方便快速使用
4. 是否有完备技术服务流程
  1. 值班人员
  2. 故障处理流程指南
  
  
  ------------------------------------------------------------------------------------------------------------
  背景知识：
  https://gridpane.com/kb/an-introduction-to-cpu-steal-i-o-wait-and-the-top-command/
Steal “st”
Here you can see there’s no steal, but sometimes neighbours on your server can potentially steal a lot of your CPU – sometimes over 50% or more.
I/O Wait “wa”
If this is high then the CPU is waiting on the IO/drives. You can exit top and install run iotop to see which process is causing the most I/O utilization on your server.
To exit top hit Ctrl+C.
You can install iotop with:
apt install iotop
